gws_refer_id, exposure_or_outcome_name, exposure_or_outcome_data_id,
chromo = '', position = '', eff_allele = '', non_eff_allele = '', beta_val = '', p_val = '',
columns_to_remove = c()) {
formatted_file_name <- paste0(exposure_or_outcome_name, "_", exposure_or_outcome_data_id, "_formatted.csv.gz")
if (file.exists(formatted_file_name)) {                                       # 格式化后的文件存在则跳过处理
return(paste0("文件已存在（", formatted_file_name, "）。跳过格式化……"))
} else { cat("开始读取数据……\n") }
if_rename <- FALSE
if (f_fmt == "tsv") { data <- read.delim(file,sep ="\t"); if_rename <- TRUE }       # 预读取 TSV 文件，并计划重命名列
else if (f_fmt == "csv") { data <- readr::read_csv(file); if_rename <- TRUE }  # 预读取 CSV 文件，并计划重命名列
else if (f_fmt == "vcf") { data <- file }                                      # VCF 文件不需要预读取
else { stop(paste0("尚未支持 ", f_fmt, " 格式。数据格式化异常退出！")) }
if (if_rename) {                                                               # 删除特定列并重命名列
data <- data %>%
select(-one_of(columns_to_remove)) %>%  # 删除指定列
select_if(~!all(is.na(.))) %>%          # 删除所有值均为 NA 的列
dplyr::rename(
CHR = chromo,         # SNP 所在染色体号
BP = position,        # SNP 所在染色体位置
A1 = eff_allele,      # 效应等位基因
A2 = non_eff_allele,  # 非效应等位基因
BETA = beta_val,      # beta 值
P = p_val             # P 值
)  # 以上 6 列必须严格声明
cat("预读取已完成，开始格式化……\n")
}
# 删除日志文件（文件名中包含“_log_”）
for (file in list.files(getwd())) { if (grepl(paste0(exposure_or_outcome_name, "_", exposure_or_outcome_data_id, "_formatted_log_.+\\.txt"), file)) { file.remove(file) } }
MungeSumstats::format_sumstats(  # 执行格式化
data,
ref_genome = gws_refer_id,                            # 用于GWAS的参考基因组标识符
dbSNP = 155,                                          # dbSNP 版本号（144 或 155）
ignore_multi_trait = TRUE,                            # 忽略多个 P 值
strand_ambig_filter = FALSE,                          # 删除具有串不明确基因的 SNP
bi_allelic_filter = FALSE,                            # 去除非双等位基因的 SNP
allele_flip_check = FALSE,                            # 对照参考基因组检查并翻转等位基因方向
indels = FALSE,                                       # 是否包含 indel 变异
nThread = 16,                                         # 并行的线程数
save_path = file.path(FMT_DIR, formatted_file_name),  # 输出格式化了的文件
log_mungesumstats_msgs = TRUE,                        # 保存日志信息
log_folder = getwd(),                                 # 日志文件夹保存路径
)
cat(paste0("格式化已完成：", formatted_file_name, "\n"))
}
# ---格式化暴露数据
format_gwas_data(file = exposure_file, f_fmt = "tsv",
gws_refer_id = EXPOSURE_REFER_ID, exposure_or_outcome_name = EXPOSURE_NAME, exposure_or_outcome_data_id = EXPOSURE_DATA_ID,
# chromo = "...", position = "...", eff_allele = "...", non_eff_allele = "...", beta_val = "...", p_val = "..."
)
gws_refer_id, exposure_or_outcome_name, exposure_or_outcome_data_id,
file = exposure_file, f_fmt = "tsv",
file = exposure_file
f_fmt = "tsv"
gws_refer_id = EXPOSURE_REFER_ID
exposure_or_outcome_name = EXPOSURE_NAME
exposure_or_outcome_data_id = EXPOSURE_DATA_ID
formatted_file_name <- paste0(exposure_or_outcome_name, "_", exposure_or_outcome_data_id, "_formatted.csv.gz")
if (file.exists(formatted_file_name)) {                                       # 格式化后的文件存在则跳过处理
return(paste0("文件已存在（", formatted_file_name, "）。跳过格式化……"))
} else { cat("开始读取数据……\n") }
if_rename <- FALSE
if (f_fmt == "tsv") { data <- read.delim(file,sep ="\t"); if_rename <- TRUE }       # 预读取 TSV 文件，并计划重命名列
if (if_rename) {                                                               # 删除特定列并重命名列
data <- data %>%
select(-one_of(columns_to_remove)) %>%  # 删除指定列
select_if(~!all(is.na(.))) %>%          # 删除所有值均为 NA 的列
dplyr::rename(
CHR = chromo,         # SNP 所在染色体号
BP = position,        # SNP 所在染色体位置
A1 = eff_allele,      # 效应等位基因
A2 = non_eff_allele,  # 非效应等位基因
BETA = beta_val,      # beta 值
P = p_val             # P 值
)  # 以上 6 列必须严格声明
cat("预读取已完成，开始格式化……\n")
}
columns_to_remove
columns_to_remove = c()
if (if_rename) {                                                               # 删除特定列并重命名列
data <- data %>%
select(-one_of(columns_to_remove)) %>%  # 删除指定列
select_if(~!all(is.na(.))) %>%          # 删除所有值均为 NA 的列
dplyr::rename(
CHR = chromo,         # SNP 所在染色体号
BP = position,        # SNP 所在染色体位置
A1 = eff_allele,      # 效应等位基因
A2 = non_eff_allele,  # 非效应等位基因
BETA = beta_val,      # beta 值
P = p_val             # P 值
)  # 以上 6 列必须严格声明
cat("预读取已完成，开始格式化……\n")
}
head(data)
colnames(data)
# ---格式化暴露数据
format_gwas_data(file = exposure_file, f_fmt = "tsv",
gws_refer_id = EXPOSURE_REFER_ID, exposure_or_outcome_name = EXPOSURE_NAME, exposure_or_outcome_data_id = EXPOSURE_DATA_ID,
chromo = "chromosome", position = "hm_pos", eff_allele = "hm_effect_allele", non_eff_allele = "hm_other_allele", beta_val = "hm_beta", p_val = "p_value"
)
# ---格式化暴露数据
format_gwas_data(file = exposure_file, f_fmt = "tsv",
gws_refer_id = EXPOSURE_REFER_ID, exposure_or_outcome_name = EXPOSURE_NAME, exposure_or_outcome_data_id = EXPOSURE_DATA_ID,
chromo = "chromosome", position = "hm_pos", eff_allele = "hm_effect_allele", non_eff_allele = "hm_other_allele", beta_val = "hm_beta", p_val = "p_value"
)
outcome_file
# ---格式化结局数据
format_gwas_data(file = outcome_file, f_fmt = "tsv",
gws_refer_id = OUTCOME_REFER_ID, exposure_or_outcome_name = OUTCOME_NAME, exposure_or_outcome_data_id = OUTCOME_DATA_ID,
chromo = "chromosome", position = "base_pair_location", eff_allele = "effect_allele", non_eff_allele = "other_allele", beta_val = "beta_fe", p_val = "p_value"
)
gc()
gc()
data_exposure <- data
file
outcome_file
file = outcome_file
gws_refer_id = OUTCOME_REFER_ID
exposure_or_outcome_name
gws_refer_id
exposure_or_outcome_name = OUTCOME_NAME
exposure_or_outcome_name
exposure_or_outcome_data_id = OUTCOME_DATA_ID
exposure_or_outcome_data_id
OUTCOME_DATA_ID
EXPOSURE_DATA_ID
file
outcome_file
data_outcome <- read.delim(file,spe = "\t")
data_outcome <- read.delim(file,sep = "\t")
gc()
rm(data)
rm(data_exposure)
rm(data_outcome)
install_if_not_installed <- function(pkg, install_function = install.packages) {
# 检查包是否安装，或指定安装函数
if (!requireNamespace(pkg, quietly = TRUE)) {
if (identical(install_function, install.packages)) {
install.packages(pkg)
} else {
install_function
}
}
}
pkgs <- c(  # 需要安装的包列表
"VariantAnnotation", "gwasglue", "dplyr", "tidyr",
"CMplot", "TwoSampleMR", "MendelianRandomization",
"LDlinkR", "ggplot2", "ggforestplot", "ggfunnel",
"cowplot", "friendly2MR", "plinkbinr", "FastDownloader",
"FastTraitR", "MRPRESSO", "SNPlocs.Hsapiens.dbSNP155.GRCh37",
"SNPlocs.Hsapiens.dbSNP155.GRCh38","BSgenome.Hsapiens.NCBI.GRCh38", "tidyverse",
'MungeSumstats', 'GenomicFiles'
)
install_if_not_installed <- function(pkg, install_function = install.packages) {
# 检查包是否安装，或指定安装函数
if (!requireNamespace(pkg, quietly = TRUE)) {
if (identical(install_function, install.packages)) {
install.packages(pkg)
} else {
install_function
}
}
}
pkgs <- c(  # 需要安装的包列表
"VariantAnnotation", "gwasglue", "dplyr", "tidyr",
"CMplot", "TwoSampleMR", "MendelianRandomization",
"LDlinkR", "ggplot2", "ggforestplot", "ggfunnel",
"cowplot", "friendly2MR", "plinkbinr", "FastDownloader",
"FastTraitR", "MRPRESSO", "SNPlocs.Hsapiens.dbSNP155.GRCh37",
"SNPlocs.Hsapiens.dbSNP155.GRCh38","BSgenome.Hsapiens.NCBI.GRCh38", "tidyverse",
'MungeSumstats', 'GenomicFiles'
)
# 未安装则安装
install_if_not_installed("devtools")
install_if_not_installed("tidyverse")
install_if_not_installed("gwasglue", devtools::install_github("mrcieu/gwasglue", force = TRUE))
install_if_not_installed("BiocManager")
install_if_not_installed("VariantAnnotation", BiocManager::install)
install_if_not_installed("dplyr")
install_if_not_installed("tidyr")
install_if_not_installed("CMplot")
install_if_not_installed("remotes")
install_if_not_installed("TwoSampleMR", remotes::install_github("MRCIEU/TwoSampleMR"))
install_if_not_installed("MendelianRandomization")
install_if_not_installed("LDlinkR")
install_if_not_installed("ggfunnel", devtools::install_github("pedropark99/ggfunnel", force = TRUE))
install_if_not_installed("ggforestplot", devtools::install_github("NightingaleHealth/ggforestplot", force = TRUE))
install_if_not_installed("friendly2MR", devtools::install_github("xiechengyong123/friendly2MR", force = TRUE))
# install_friendly2MR_dependence()
install_if_not_installed("plinkbinr", devtools::install_github("explodecomputer/plinkbinr", force = TRUE))
# https://flash0926.yuque.com/org-wiki-flash0926-kivyu0/otdnsb/tluzaguvye4t9l08
install_if_not_installed("FastDownloader")
install_if_not_installed("FastTraitR", FastDownloader::install_pkg("FastTraitR"))
install_if_not_installed("MRPRESSO")
install_if_not_installed("SNPlocs.Hsapiens.dbSNP155.GRCh37", BiocManager::install("SNPlocs.Hsapiens.dbSNP155.GRCh37"))
install_if_not_installed("SNPlocs.Hsapiens.dbSNP155.GRCh38", BiocManager::install("SNPlocs.Hsapiens.dbSNP155.GRCh38"))
install_if_not_installed("BSgenome.Hsapiens.NCBI.GRCh38", BiocManager::install("BSgenome.Hsapiens.NCBI.GRCh38"))
install_if_not_installed("MungeSumstats", BiocManager::install("MungeSumstats"))
install_if_not_installed("GenomicFiles", BiocManager::install("GenomicFiles"))
# 导入包
lapply(pkgs, function(pkg) {
suppressMessages(library(pkg, character.only = TRUE, quietly = TRUE))
})
#rm(list = ls())  # 包初始化结束
# 抽取数据集子集
extract_subset <- function(file_path, b = 1, N, subset_file) {
head_lines <- readr::read_lines(file_path, skip = 0, n_max = b)
remaining_lines <- readr::read_lines(file_path, skip = b + 1)
sample_lines <- sample(remaining_lines, N)
write_lines(c(head_lines, sample_lines), subset_file)
}
# ---GWAS 数据暴露因素和结局简称、标识符、参考基因组标识符、人群类别
EXPOSURE_NAME <- 'HbA1c'     # 数据名称。建议使用英文简称，如 WBC、BMI 等
EXPOSURE_DATA_ID <- 'UKB_HbA1c'  # 数据标识符。建议使用英文简称，如 UK_Biobank_BMI 等
EXPOSURE_REFER_ID <- 'GRCh38' # GWAS 数据所用的参考序列版本，如 GRCh37 等
EXPOSURE_POP <- 'EUR'      # 人口学种群标识，如 AFR（非洲）、AMR（美洲）、EAS（东亚）、EUR（欧洲）、SAS（南亚）
OUTCOME_NAME <- 'PD'
OUTCOME_DATA_ID <- '2024_Multi'
OUTCOME_REFER_ID <- 'GRCh38'
OUTCOME_POP <- 'EUR'
# 千人基因组计划中用于 LD 参考的数据集位置
LD_REF <- 'D:/MR_Data/LD_Ref/1kg.v3'  # 下载 http://fileserve.mrcieu.ac.uk/ld/1kg.v3.tgz 文件，解压归档。保证该目录下有可用的 .bed、.bim 和 .fam 文件
# ---分析结果的根目录。必须预先手动创建
root_dir <- 'D:/MR_Data/MendelRookie_output'
# 子文件夹名
topic <- paste0(EXPOSURE_NAME, '(', EXPOSURE_DATA_ID, ')', '→', OUTCOME_NAME, '(', OUTCOME_DATA_ID, ')')
fmt <- '#_FORMATED_DATA'                   # 数据格式化
cor <- '1_correlation_analysis'            # 相关性分析
ld <- '2_linkage_disequilibrium_analysis'  # 连锁不平衡分析
mr_weak <- '3_remove_weak_IV'              # 弱工具变量剔除
mr_con <- '4_remove_confounder'            # 混杂因素剔除
mr <- '5_do_MR'                            # 孟德尔随机化分析
# 子文件夹路径
FMT_DIR <- file.path(root_dir, fmt)
TOPIC_DIR <- file.path(root_dir, topic)
COR_DIR <- file.path(root_dir, topic, cor)
LD_DIR <- file.path(root_dir, topic, ld)
MR_WEAK_DIR <- file.path(root_dir, topic, mr_weak)
MR_CON_DIR <- file.path(root_dir, topic, mr_con)
MR_DIR <- file.path(root_dir, topic, mr)
dirs <- list(FMT_DIR, TOPIC_DIR, COR_DIR, LD_DIR, MR_WEAK_DIR, MR_CON_DIR, MR_DIR)
# 文件目录与 #confounder_SNPs.txt 文件初始化
for (dir in dirs) { if (!dir.exists(dir)) { dir.create(dir) } }
confounder_file <- file.path(MR_CON_DIR, '#confounder_SNPs.txt')
if (!file.exists(confounder_file)) { file.create(confounder_file) }
# 移除无用的变量
GLOBAL_VAR <- c('EXPOSURE_NAME', 'OUTCOME_NAME',  # 暴露因素和结局的简称
'EXPOSURE_DATA_ID', 'OUTCOME_DATA_ID',  # GWAS 数据标识符
'EXPOSURE_REFER_ID', 'OUTCOME_REFER_ID',  # 参考基因组标识符
'EXPOSURE_POP', 'OUTCOME_POP',  # 人群类别
'LD_REF',  # 用于 LD 参考的数据集位置
'FMT_DIR', 'COR_DIR', 'LD_DIR', 'MR_WEAK_DIR', 'MR_CON_DIR', 'MR_DIR',  # 子文件夹路径
'GLOBAL_VAR')
setwd(FMT_DIR); cat("当前工作目录：", getwd())
exposure_file <- "D:/MR_Data/GWAS_Data/GCST90014006/harmonised/harmonised.qc.tsv"  # GWAS数据，用作暴露因素
outcome_file <- "D:/MR_Data/GWAS_Data/GCST90275127/harmonised/GCST90275127.h.tsv"   # GWAS数据，用作结局
setwd(COR_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(FMT_DIR, paste0(EXPOSURE_NAME, "_", EXPOSURE_DATA_ID, "_formatted.csv.gz"))
P_THRESHOLD <- 5e-05  # SNPs 筛选的阈值（建议值：5e-8）
# ---读取数据完成了格式化的数据
exposure_data <- TwoSampleMR::read_exposure_data(  # 注意列名！
filename = exposure_csv_file, sep = ',',
snp_col = 'SNP', chr_col = 'CHR', pos_col = 'BP',
effect_allele_col = 'A1', other_allele_col = 'A2',
beta_col = 'BETA', se_col = 'SE', eaf_col = 'FRQ', pval_col = 'P',
samplesize_col = 'N',
)
# ---必要时补齐 samplesize.exposure 列
if (all(is.na(exposure_data$samplesize.exposure))) {
while (TRUE) {
num <- readline(prompt = "samplesize.exposure 列缺失，请根据数据来源（网页、MataInfo、文献等）将该列填充为统一数值：")
if (grepl("^\\d+\\.?\\d*$", num)) {
exposure_data$samplesize.exposure <- as.numeric(num)
message("已将 ", num, " 填充至 samplesize.exposure 列")
break
} else { stop("输入有误！只支持数值型") }
}
}
# ---必要时补齐 samplesize.exposure 列
if (all(is.na(exposure_data$samplesize.exposure))) {
while (TRUE) {
num <- readline(prompt = "samplesize.exposure 列缺失，请根据数据来源（网页、MataInfo、文献等）将该列填充为统一数值：")
if (grepl("^\\d+\\.?\\d*$", num)) {
exposure_data$samplesize.exposure <- as.numeric(num)
message("已将 ", num, " 填充至 samplesize.exposure 列")
break
} else { stop("输入有误！只支持数值型") }
}
}
# ---必要时补齐 samplesize.exposure 列
if (all(is.na(exposure_data$samplesize.exposure))) {
while (TRUE) {
num <- readline(prompt = "samplesize.exposure 列缺失，请根据数据来源（网页、MataInfo、文献等）将该列填充为统一数值：")
if (grepl("^\\d+\\.?\\d*$", num)) {
exposure_data$samplesize.exposure <- as.numeric(num)
message("已将 ", num, " 填充至 samplesize.exposure 列")
break
} else { stop("输入有误！只支持数值型") }
}
}
# ---滤去关联性弱的 SNP 并输出到文件
output_data <- subset(exposure_data, pval.exposure < P_THRESHOLD)
cat(paste("剩余", nrow(output_data), "个 SNP"))
write.csv(output_data, file = 'exposure.pvalue.csv', row.names = FALSE); file.create(paste0("exposure.pvalue.csv - P＜", P_THRESHOLD))
# ---绘制曼哈顿图：准备数据并绘图输出
exposure_data <- exposure_data[, c("SNP", "chr.exposure", "pos.exposure", "pval.exposure")]
colnames(exposure_data) <- c("SNP", "CHR", "BP", "pvalue")
CMplot(exposure_data,
plot.type = "m",  # m：线性曼哈顿图
LOG10 = TRUE, threshold = P_THRESHOLD, threshold.lwd = 3, threshold.lty = 1, signal.cex = 0.2,
chr.den.col = NULL, cex = 0.2, bin.size = 1e5, ylim = c(0, 50), width = 15, height = 9,
file.output = TRUE, file = output_fmt, verbose = TRUE
)
output_fmt
setwd(COR_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(FMT_DIR, paste0(EXPOSURE_NAME, "_", EXPOSURE_DATA_ID, "_formatted.csv.gz"))
P_THRESHOLD <- 5e-05  # SNPs 筛选的阈值（建议值：5e-8）
output_fmt <- "png"   # 支持的格式：jpg、pdf、tiff、png
CMplot(exposure_data,
plot.type = "m",  # m：线性曼哈顿图
LOG10 = TRUE, threshold = P_THRESHOLD, threshold.lwd = 3, threshold.lty = 1, signal.cex = 0.2,
chr.den.col = NULL, cex = 0.2, bin.size = 1e5, ylim = c(0, 50), width = 15, height = 9,
file.output = TRUE, file = output_fmt, verbose = TRUE
)
setwd(LD_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(COR_DIR, "exposure.pvalue.csv")
CLUMP_KB <- 500  # 连锁互换的距离（建议值：10000）
CLUMP_R2 <- 0.1  # 连锁互换的 R² 阈值（建议值：0.001）
# ---读取暴露数据
exposure_data <- read.csv(exposure_csv_file, header = TRUE, sep = ",", check.names = FALSE)
# ---去除连锁不平衡的 SNP 并保存
unclump_snps <- ieugwasr::ld_clump(dat = dplyr::tibble(rsid = exposure_data$SNP, pval = exposure_data$pval.exposure, id = exposure_data$id.exposure),
clump_kb = CLUMP_KB,
clump_r2 = CLUMP_R2,
plink_bin = get_plink_exe(),
bfile = file.path(LD_REF, EXPOSURE_POP))
exposure_data <- exposure_data %>%
dplyr::inner_join(unclump_snps, by = c("SNP" = "rsid")) %>%
dplyr::select(names(.))
print(paste("剩余", nrow(exposure_data), "个 SNP"))
write.csv(exposure_data, file = "exposure.LD.csv", row.names = FALSE); file.create(paste0("exposure.LD.csv - ", CLUMP_KB, " kb, ", CLUMP_R2, "R²"))
rm(list = setdiff(ls(), GLOBAL_VAR))  # 移除无用的变量
gc()
exposure_data
setwd(MR_WEAK_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(LD_DIR, "exposure.LD.csv")
exposure_csv_file
F_THRESHOLD <- 10  # F 统计量阈值
# ---读取连锁不平衡分析结果文件
exposure_data <- read.csv(exposure_csv_file, header = TRUE, sep = ",", check.names = FALSE)
# ---补齐 R² 和 F 列
exposure_data$R2 <- TwoSampleMR::get_r_from_bsen(exposure_data$beta.exposure, exposure_data$se.exposure, exposure_data$samplesize.exposure)^2
exposure_data$Fval <- (exposure_data$samplesize.exposure - 2) * exposure_data$R2 / (1 - exposure_data$R2)
# ---过滤保留 F>10 的工具变量
exposure_data <- exposure_data[exposure_data$F > F_THRESHOLD,]
print(paste("剩余", nrow(exposure_data), "个 SNP"))
write.csv(exposure_data, "exposure.F.csv", row.names = FALSE); file.create(paste0("exposure.F.csv - F＞", F_THRESHOLD))
rm(list = setdiff(ls(), GLOBAL_VAR))  # 移除无用的变量
setwd(MR_CON_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(MR_WEAK_DIR, "exposure.F.csv")
# ---读取去除了弱工具变量的结果文件
exposure_data <- read.csv(exposure_csv_file, header = TRUE, sep = ",", check.names = FALSE)
# 获取当前的工具变量表型并保存到文件
snp_with_trait <- FastTraitR::look_trait(rsids = exposure_data$SNP, out_file = 'check_SNPs_trait.csv')
snp_with_trait_save <- snp_with_trait %>%
arrange(trait) %>%
select(trait) %>%
distinct()  # 工具变量表型去重
writeLines(snp_with_trait_save$trait, 'check_SNPs_trait.txt')  # 保存到文件
print(paste("当前筛选到的 SNPs 表型描述，按行分隔地保存到了 check_SNPs_trait.txt 文件～"))
# ----👇手动整理混杂因素列表----
message(paste0("查看 check_SNPs_trait.txt 文件中的表型是否为 [", EXPOSURE_NAME, " → ", OUTCOME_NAME, "] 的混杂因素，\n将混杂因素保存到 ./4_remove_confounder/#confounder_SNPs.txt 文件！"))
if (file.info("#confounder_SNPs.txt")$size == 0) { stop("请手动整理混杂因素列表文件 #confounder_SNPs.txt！") }
# ----👇手动整理混杂因素列表----
message(paste0("查看 check_SNPs_trait.txt 文件中的表型是否为 [", EXPOSURE_NAME, " → ", OUTCOME_NAME, "] 的混杂因素，\n将混杂因素保存到 ./4_remove_confounder/#confounder_SNPs.txt 文件！"))
if (file.info("#confounder_SNPs.txt")$size == 0) { stop("请手动整理混杂因素列表文件 #confounder_SNPs.txt！") }
# ---比较并剔除包含在文本文件中的短语的 SNP，并保存到文件
confounders <- readLines("#confounder_SNPs.txt")
snp_with_trait$trait <- tolower(snp_with_trait$trait)  # 确保 trait 列文本均为小写
for (confounder in confounders) {
snp_with_trait <- snp_with_trait[!grepl(tolower(confounder), snp_with_trait$trait),]
}
snp_with_trait <- dplyr::distinct(snp_with_trait, rsid, .keep_all = FALSE)  # 去重
exposure_data <- exposure_data %>%
dplyr::inner_join(snp_with_trait, by = c("SNP" = "rsid")) %>%
dplyr::select(names(exposure_data))
print(paste("剔除混杂因素后，剩余", nrow(exposure_data), "个 SNP"))
print(paste("剩余", nrow(exposure_data), "个 SNP"))
write.csv(exposure_data, "exposure.confounder.csv", row.names = FALSE)
setwd(MR_DIR); cat("当前工作目录：", getwd())
exposure_csv_file <- file.path(MR_CON_DIR, "exposure.confounder.csv")
outcome_file <- file.path(FMT_DIR, paste0(OUTCOME_NAME, "_", OUTCOME_DATA_ID, "_formatted.csv.gz"))
# ---读取整理好的暴露数据
exposure_data <- read.csv(exposure_csv_file, header = TRUE, sep = ",", check.names = FALSE)
# ---读取结局数据
outcome_data <- TwoSampleMR::read_outcome_data(  # 注意列名！
filename = outcome_file, sep = ',',
snp_col = 'SNP',
effect_allele_col = 'A1', other_allele_col = 'A2',
beta_col = 'BETA', se_col = 'SE', eaf_col = 'FRQ', pval_col = 'P'
)
# ---筛选结局数据中，与工具变量相交集的部分，并输出到文件
outcome_table <- merge(exposure_data, outcome_data, by.x = "SNP", by.y = "SNP")
write.csv(outcome_table[, -(2:ncol(exposure_data))], file = "outcome.csv")
rm(outcome_table)
# ---将暴露数据和结局数据打标签后整合到一个数据框
exposure_data$exposure <- EXPOSURE_NAME
outcome_data$outcome <- OUTCOME_NAME
data <- TwoSampleMR::harmonise_data(exposure_data, outcome_data, action = 1)
# ---输出工具变量
write.csv(data[data$mr_keep == "TRUE",], file = "SNP.csv", row.names = FALSE)
# ---MR-PRESSO 方法进行异常值检测，得到偏倚的 SNP
mr_presso_result <- run_mr_presso(data)
write.csv(mr_presso_result[[1]]$
`MR-PRESSO results`$
`Outlier Test`, file = "outlier_SNPs.csv")
# ---执行孟德尔随机化分析
mr_result <- mr(data)
write.csv(generate_odds_ratios(mr_result), file = "MR-Result.csv", row.names = FALSE)
# ---异质性检验
write.csv(mr_heterogeneity(data), file = "heterogeneity.csv", row.names = FALSE)
# ---多效性检验
write.csv(mr_pleiotropy_test(data), file = "pleiotropy.csv", row.names = FALSE)
# ---绘图
pdf(file = "pic.scatter_plot.pdf", width = 7.5, height = 7); mr_scatter_plot(mr_result, data); dev.off()  # 散点图
res_single <- mr_singlesnp(data)
pdf(file = "pic.forest.pdf", width = 7, height = 6.5); mr_forest_plot(res_single); dev.off()  # 森林图
pdf(file = "pic.funnel_plot.pdf", width = 7, height = 6.5); mr_funnel_plot(singlesnp_results = res_single); dev.off()  # 漏斗图
pdf(file = "pic.leaveoneout.pdf", width = 7, height = 6.5); mr_leaveoneout_plot(leaveoneout_results = mr_leaveoneout(data)); dev.off()  # 敏感性分析
rm(list = setdiff(ls(), GLOBAL_VAR))  # 移除无用的变量
gc()  # 垃圾回收
setwd(MR_DIR); cat("当前工作目录：", getwd())
result_file <- file.path(MR_DIR, "MR-Result.csv")
pFilter <- 1  # 是否根据 P 值过滤？1：不过滤；0.05：过滤
draw_forest_map <- function(inputFile = null, forestFile = null, forestCol = null) {
# 读取输入文件
rt <- read.csv(inputFile, header = T, sep = ",", check.names = F)
row.names(rt) <- rt$method
rt <- rt[rt$pval < pFilter,]
method <- rownames(rt)
or <- sprintf("%.3f", rt$"or")
orLow <- sprintf("%.3f", rt$"or_lci95")
orHigh <- sprintf("%.3f", rt$"or_uci95")
OR <- paste0(or, "(", orLow, "-", orHigh, ")")
pVal <- ifelse(rt$pval < 0.001, "<0.001", sprintf("%.3f", rt$pval))
#输出图形
pdf(file = forestFile, width = 7, height = 4.6)
n <- nrow(rt)
nRow <- n + 1
ylim <- c(1, nRow)
layout(matrix(c(1, 2), nc = 2), width = c(3.5, 2))
# 左侧
xlim <- c(0, 3)
par(mar = c(4, 2.5, 2, 1))
plot(1, xlim = xlim, ylim = ylim, type = "n", axes = F, xlab = "", ylab = "")
text.cex <- 0.8
text(0, n:1, method, adj = 0, cex = text.cex)
text(1.9, n:1, pVal, adj = 1, cex = text.cex); text(1.9, n + 1, 'pvalue', cex = 1, font = 2, adj = 1)
text(3.1, n:1, OR, adj = 1, cex = text.cex); text(2.7, n + 1, 'OR', cex = 1, font = 2, adj = 1)
# 右侧
par(mar = c(4, 1, 2, 1), mgp = c(2, 0.5, 0))
xlim <- c(min(as.numeric(orLow) * 0.975, as.numeric(orHigh) * 0.975, 0.9), max(as.numeric(orLow), as.numeric(orHigh)) * 1.025)
plot(1, xlim = xlim, ylim = ylim, type = "n", axes = F, ylab = "", xaxs = "i", xlab = "OR")
arrows(as.numeric(orLow), n:1, as.numeric(orHigh), n:1, angle = 90, code = 3, length = 0.05, col = "darkblue", lwd = 3)
abline(v = 1, col = "black", lty = 2, lwd = 2)
boxcolor <- ifelse(as.numeric(or) > 1, forestCol, forestCol)
points(as.numeric(or), n:1, pch = 15, col = boxcolor, cex = 2)
axis(1)
dev.off()
}
draw_forest_map(inputFile = result_file, forestFile = "forest_map.pdf", forestCol = "red")
rm(list = setdiff(ls(), GLOBAL_VAR))  # 移除无用的变量
setwd(MR_DIR); cat("当前工作目录：", getwd())
result_file <- file.path(MR_DIR, "MR-Result.csv")
pFilter <- 1  # 是否根据 P 值过滤？1：不过滤；0.05：过滤
draw_forest_map <- function(inputFile = null, forestFile = null, forestCol = null) {
# 读取输入文件
rt <- read.csv(inputFile, header = T, sep = ",", check.names = F)
row.names(rt) <- rt$method
rt <- rt[rt$pval < pFilter,]
method <- rownames(rt)
or <- sprintf("%.3f", rt$"or")
orLow <- sprintf("%.3f", rt$"or_lci95")
orHigh <- sprintf("%.3f", rt$"or_uci95")
OR <- paste0(or, "(", orLow, "-", orHigh, ")")
pVal <- ifelse(rt$pval < 0.001, "<0.001", sprintf("%.3f", rt$pval))
#输出图形
pdf(file = forestFile, width = 7, height = 4.6)
n <- nrow(rt)
nRow <- n + 1
ylim <- c(1, nRow)
layout(matrix(c(1, 2), nc = 2), width = c(3.5, 2))
# 左侧
xlim <- c(0, 3)
par(mar = c(4, 2.5, 2, 1))
plot(1, xlim = xlim, ylim = ylim, type = "n", axes = F, xlab = "", ylab = "")
text.cex <- 0.8
text(0, n:1, method, adj = 0, cex = text.cex)
text(1.9, n:1, pVal, adj = 1, cex = text.cex); text(1.9, n + 1, 'pvalue', cex = 1, font = 2, adj = 1)
text(3.1, n:1, OR, adj = 1, cex = text.cex); text(2.7, n + 1, 'OR', cex = 1, font = 2, adj = 1)
# 右侧
par(mar = c(4, 1, 2, 1), mgp = c(2, 0.5, 0))
xlim <- c(min(as.numeric(orLow) * 0.975, as.numeric(orHigh) * 0.975, 0.9), max(as.numeric(orLow), as.numeric(orHigh)) * 1.025)
plot(1, xlim = xlim, ylim = ylim, type = "n", axes = F, ylab = "", xaxs = "i", xlab = "OR")
arrows(as.numeric(orLow), n:1, as.numeric(orHigh), n:1, angle = 90, code = 3, length = 0.05, col = "darkblue", lwd = 3)
abline(v = 1, col = "black", lty = 2, lwd = 2)
boxcolor <- ifelse(as.numeric(or) > 1, forestCol, forestCol)
points(as.numeric(or), n:1, pch = 15, col = boxcolor, cex = 2)
axis(1)
dev.off()
}
draw_forest_map(inputFile = result_file, forestFile = "forest_map.pdf", forestCol = "red")
rm(list = setdiff(ls(), GLOBAL_VAR))  # 移除无用的变量
